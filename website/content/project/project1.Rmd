---
title: "Project 1"
author: "Elena Koung ek8753"
date: "`r Sys.Date()`"
---

## Introduction

I chose to examine my Spotify listening data by combining my music streaming history. I acquired this data easily by requesting it through Spotify and waiting a few days and it was emailed to me in a .zip folder. 
My two datasets (StreamingHistory0 and StreamingHistory1) are identical in structure and the variables I see are endTime, artistName, trackName, and msPlayed. While this is just 4 variables, I can split endTime into year, month, day, and time (hour and minute) to examine more numerical variables to fit the rubric. The common variable is probably going to be artistName and the numerical (at least 3) variacles will be year, month, day, time, and msPlayed. I also think I want to change msPlayed into seconds and minutes because it is easier to understand/think about. 


## Detail of Variables
```yaml
A list of items (songs, videos, and podcasts) listened to or watched in the past year:

endTime: Date and time of when the stream ended in UTC format.
artistName: Name of creator for each stream (the artist name if a music track).
trackName: Name of items listened to/watched (title of music track/name of video). 
msPlayed: Stands for how many mili-seconds the track was listened. 

```
## Interest

I am interested in my Spotify data because I use Spotify as my #1 music streaming service and used it almost every week when I play video games. I want to see what weeks I spent a lot of time listening to music, especially since COVID started, I feel like I listen to music less since I don't get my walk-to-class music anymore. I also listen to music less when I have depression, so there may be periods of time I don't listen to music at all. I definitely gravitate towards some playlists depending on moods so seeing what the top artist of every day would be a cool thing to analyze. 

It is also cool because I get to listen along with friends through the app and wonder if it counts into my own streaming history as well. I am interested to see how the data I wrangle compares to my Spotify wrapped and see if there are the same conclusions! 
```yaml
Some potential associations that I expect to see are:
Alan Walker or Taylor Swift as a most frequently listened to artist
Results match my Spotify Wrapped data so there shouldn't be any surprises 

```
I can't really tell what my most played song would be, but definitely from one of those two artists above.

## Loading json 

```{r fig.width=6, fig.height=6, fig.align='center'}
library("rjson")
library(tidyverse)
library(cluster)

list1 = rjson::fromJSON(file = "StreamingHistory0.json")
list2 = rjson::fromJSON(file = "StreamingHistory1.json")
list1 <- do.call(rbind, lapply(list1, data.frame))
list2 <- do.call(rbind, lapply(list2, data.frame))
```

## Tidy it!
```{r fig.width=6, fig.height=6, fig.align='center'}

streaming <- full_join(list1, list2) %>% glimpse
```
The datasets are already tidy. 

## Joining!

```{r fig.width=6, fig.height=6, fig.align='center'}

streaming <- full_join(list1, list2) 
streaming2 <- streaming %>% separate(endTime, sep="-", into=c("year", "monthNum","dayTime")) %>%
    mutate(new = str_replace_all(dayTime, " ", "_")) %>% separate(new, sep="_", into=c("day", "time")) %>% mutate(month = recode(monthNum, "01"="Jan","02"="Feb","03"="Mar","04"="Apr","05"="May","06"="Jun", "07"="Jul","08"="Aug","09"="Sep","10"="Oct","11"="Nov","12"="Dec"))
streaming2 %>% glimpse()
```
First I used `full_join` to combine the datasets. The datasets are identical in structure and I wanted to preserve all observations, so this function made the most sense to do. In the original datasets, `list1` and `list2`, they had 10000 rows and 4 columns and 2846 rows and 4 columns, respectively. Thus, it was expected that after the `full_join` that we would see a dataset with 12486 rows and 4 columns. 

I wanted to have more then 3 numerical variables. The original variable `endTime` was split using `separate()` into `year`, `monthNum`, and `dayTime`. Since `dayTime` was formatted with a space, I used `mutate()` to change the space with an underscore so it was able to separate based on the underscore into new columns- `day` and `time`. Then since month is a character value and not numerical, I used recode to rename all of the numbered months into their month abbreviations. 



## Wrangling!

```{r fig.width=6, fig.height=6, fig.align='center'}

streaming3 <- streaming2 %>% mutate(sPlayed = msPlayed / 1000) %>% mutate(minPlayed = sPlayed / 60)
streaming3 %>% arrange(desc(minPlayed)) %>% glimpse()
streaming3 %>% group_by(trackName,minPlayed) %>% filter(n()>1) %>% summarize(count=n()) %>% arrange(desc(count)) %>% glimpse()

#streaming3 %>% select(artistName, trackName, minPlayed) %>% group_by(artistName, trackName) %>% summarize_if(is.numeric, list(mean=mean, sd=sd, min=min, max=max))
```
I used `mutate` to change `msPlayed` (in milliseconds) to different units: seconds and minutes. So all I did was divide `msPlayed`by 1000 to get `sPlayed` (in seconds) and divide `sPlayed` by 60 to get `minPlayed` (in minutes).

I wanted to see what the longest song I listened to was, so I used `arrange()` to order `minPlayed` in descending order to reveal the longest song. It turns out to be 3 hour White Noise! This is not what I expected because I forgot that streaming history includes podcasts as well as these sleep "songs".

When I use `group_by()` on `trackName` and `minPlayed` to get each song grouped by how long it was played. This let me see that there are times I skipped the same song while also listening to it a certain amount of time. Basically, while I could count the total amount of times I've listened each song through counting each appearance, I am more interested in how many full plays of a song I went through.

So, looking at `minPlayed`, I see that there are a few times I will skip a song before it is fully played through (probably because I was on shuffle and just wasn't vibing to a particular song). I don't want this to count to my total number of streams. Thus, I used `filter()` with count greater than 1 as my argument, to remove any instances of "skipping" the song. While `minPlayed` is not a categorical variable, it acts as one when I group by it to check if "yes/no" the song has been played fully. 

Then I use `summarize()` with `n()` as the argument, I get a list of songs and how many times they were played FULLY. I `arrange()` by descending order to see which song I've played the most. For my most listened song, I see that I have listened to "Let's Fall in Love for the Night" 40 times in the past year! I am surprised because this isn't one of my favorite songs, but also looks like I never really skip it either! 

## Tidying summarized data
```{r fig.width=6, fig.height=6, fig.align='center'}

streaming4 <- streaming3 %>% group_by(trackName) %>% summarize_if(is.numeric, list(mean=mean, sd=sd, min=min, max=max))
streaming5 <- streaming4 %>% pivot_longer(contains("_")) %>% separate(name, sep="_", into=c("1", "Stat")) %>% pivot_wider(names_from="1", values_from="value") %>% arrange(desc(minPlayed)) %>% glimpse()

```
Since I used `n()` earlier in `summarize()`, I chose to look at 4 other functions inside this function. I was able to look at all the songs I streamed and summarize their mean, standard deviation, min, max through `summarize_if`. First, I `pivot_longer` to look at all of the data that resulted from the summarize, so it has a `name` and `value` associated with each statistic. Then I used `separate()` to split the quantifier (ms, s, minPlayed) from the type of statistic (mean, sd, min, max). After that I used `pivot_wider` to change the row labels into column labels and matched the associated values to each quantifier and statistic. Then I arranged in descending order to look at the maximum amount of time I spent streaming: "White Noise 3 Hour Long" for 180.469833! The whole duration! I guess I fell asleep to that. 

## Changing to numeric
```{r fig.width=6, fig.height=6, fig.align='center'}
data_num <- as.data.frame(apply(streaming2, 2, as.numeric)) 
sapply(data_num, class) 
```

## Visualizing Correlation 

```{r fig.width=6, fig.height=6, fig.align='center'}

cormat <- data_num %>% select(year,monthNum,day,msPlayed) %>% cor(use="pair")
tidycor <- cormat %>% as.data.frame %>% rownames_to_column("var1") %>% pivot_longer(-1,names_to="var2",values_to="correlation")

tidycor %>% ggplot(aes(var1,var2,fill=correlation)) + geom_tile() + scale_fill_gradient2(low="purple",mid="cyan",high="pink")+geom_text(aes(label=round(correlation,2)),color="black",size=5) + coord_fixed() + labs(title="Correlation of Date (day, month, year) and Time Played (ms)")

cormat2 <- streaming4 %>% select(minPlayed_mean,minPlayed_sd,minPlayed_min,minPlayed_max) %>% cor(use="pair")
tidycor <- cormat2 %>% as.data.frame %>% rownames_to_column("var1") %>% pivot_longer(-1,names_to="var2",values_to="correlation") 

tidycor %>% ggplot(aes(var1,var2,fill=correlation)) + geom_tile() + scale_fill_gradient2(low="white",mid="cyan",high="pink")+geom_text(aes(label=round(correlation,2)),color="black",size=5)+coord_fixed() + labs(title="Correlation of Statistics") + theme(axis.text.x=element_text(angle=90))
```
I made 2 correlation plots in ggplot. For "Correlation of Date (day, month, year) and Time Played (ms)": I see that month is highly correlated to year, which makes sense. It also makes sense that there is no correlation between the date and how long I listen to a song for, because I enjoy music all the time and any time. 
For "Correlation of Statistics": I see that everything is pretty highly correlated together with the exception of `minPlayed_max` and `minPlayed_sd`. It has a significantly different correlation value. It is interesting that `minPlayed_max` is most correlated with `minPlayed_mean`.


## Visualizing Plots
```{r fig.width=6, fig.height=6, fig.align='center'}
streaming3 %>% ggplot(aes(monthNum, color=factor(year))) + geom_bar(fill="pink") +labs(title="Number of Songs Played by Month", x="Month") + geom_text(aes(label = ..count..), stat = "count", vjust = 1.7, color = "purple", size=3.5) + scale_y_continuous(name="count", breaks=seq(0,3000,500))

```
In `factor(year)`, I wanted to see what year the data was from and how many counts are associated with each year. There is one observation from 2019 in December that does not show up in the data since the counts are so high (the y-max is 3000 so representing 1 count is impossible to see, therefore we see no "red" factor in the bar plot). It is interesting that I didn't listen to *any* songs in January AND February of 2020. I can't tell if this is an error or if I just completely neglected Spotify during that time in my life. My Spotify usage shot up in the months of November and December of 2020 and that was when I started playing a lot more video games and started sharing music with my friends!
It's possible was listening to downloaded music instead of streaming songs for January AND February which would account for the "error" of missing data for 2 months. 


## Clustering 
```{r fig.width=6, fig.height=6, fig.align='center'}
clust_dat<-streaming4 %>% dplyr::select(minPlayed_max,minPlayed_mean)
pam1 <- clust_dat %>% na.omit() %>% pam(2)
pamclust<-clust_dat %>% mutate(cluster=as.factor(pam1$clustering))
pamclust %>% ggplot(aes(minPlayed_max,minPlayed_mean,color=cluster)) + geom_point()
```

Need to remove outliers cus it looks funny and too hard to understand what is going on here. 
```{r fig.width=6, fig.height=6, fig.align='center'}

clust_dat<-streaming4 %>% filter(minPlayed_mean <20) %>% dplyr::select(minPlayed_max,minPlayed_mean)
pam2 <- clust_dat %>% na.omit() %>% pam(2)
pamclust<-clust_dat %>% mutate(cluster=as.factor(pam2$clustering))
pamclust %>% ggplot(aes(minPlayed_max,minPlayed_mean,color=cluster)) + geom_point()


sil_width<-vector()
for(i in 2:10){
  pam_fit <- pam(clust_dat, k = i)
  sil_width[i] <- pam_fit$silinfo$avg.width
}
ggplot()+geom_line(aes(x=1:10,y=sil_width))+scale_x_continuous(name="k",breaks=1:10)
```
Outliers (the super long white noise sleep "song") are removed. I see that in the sil width plot that the highest points are at 2 or 3 so I will choose 2 or 3 clusters. 2 looks to be the most promising for best sil width, so I will use 2 clusters. 

```{r fig.width=6, fig.height=6, fig.align='center'}
clust_dat<-streaming4 %>% filter(minPlayed_mean <4) %>% dplyr::select(minPlayed_max,minPlayed_mean)
pam3 <- clust_dat %>% na.omit() %>% pam(2)
pamclust<-clust_dat %>% mutate(cluster=as.factor(pam3$clustering))
pamclust %>% ggplot(aes(minPlayed_max,minPlayed_mean,color=cluster)) + geom_point()
```

```{r fig.width=6, fig.height=6, fig.align='center'}
pam3$silinfo$avg.width

```

With an average silhouette width of `0.665955`, the structure is a strongly moderate. I think that 2-3 clusters makes sense because there are clusters of songs played in 2020 and in 2021. Moreover, I can cluster a song's play time into skipped songs (usually less than 2 minutes), songs played through (3-5 minutes), podcasts (10+ minutes) which is really interesting to see when I look at how well each number of cluster's sil width tests goodness of fit. 

```{r fig.width=6, fig.height=6, fig.align='center'}
streaming6 <- streaming3 %>% mutate_if(is.character, as.factor)
gower1 <- daisy(streaming6, metric="gower")
pam4 <- pam(gower1,k=3,diss=T)
pamclustc <- streaming6 %>% mutate(cluster=as.factor(pam4$clustering))
pamclustc %>% ggplot(aes(day, minPlayed, color=cluster)) + geom_point()
pam4$silinfo$avg.width
```
When I used gower's, it looks like the sil width is really really small: 0.1498925. This means that no substantial structure has been found. 
I think this makes sense because there isn't supposed to be a trend in streamed songs and trying to understand the streaming history without knowledge of playlist clusters could be difficult. For future study,  I'm thinking about adding my playlist data and possible grouping and clustering on that and that might give more interesting results. 

## Conclusion

Overall, this project was really fun and interesting to work with since the data is unique to me and has a personal element to it. I think the most surprising thing was that my most played song is actually not by any of my favorite artists, but helped me discover something I didn't really pay attention to before. I had a hard time with PAM since my data was little in characteristics but large in number. I would like to run my code on other people's data (like my friend's) to see if I could help them discover something new about themselves as well! 