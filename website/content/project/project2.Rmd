---
title: "Project 2"
author: "Elena Koung ek8753"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---
```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```
## Introduction
This is a fun dataset and I'm really excited to explore the techniques we learned in class on it. I got this dataset off of Kaggle after looking for esports related data. I am a long time gamer and want to apply my statistical analysis skills to my passion: esports. As someone who has participated and won a variety of tournaments, this dataset contains data that describes the game, its total tournaments, the total payouts, and how many winners for each game. There are 520 total observations. This means there are 520 games. 


## Detail of Variables
```yaml
Variables and their descriptions:

Game: Game name.
ReleaseDate: Release Date of game.
Genre: Genre of game.
TotalEarnings: Total prizepool allocated in tournaments.
OnlineEarnings: Total prizepool allocated in online only tournaments.
TotalPlayers: Total amount of players who received a prize
TotalTournaments: Total amount of tournaments in the site
```
## Uploading the data!
```{r fig.width=6, fig.height=6, fig.align='center'}
esport <- read.csv("GeneralEsportData.csv")
```
I was really glad that the dataset is clean and ready to use :)

## MANOVA!
```{r fig.width=10, fig.height=10, fig.align='center'}
esport %>% group_by(Genre) %>% summarize(n())

man <- manova(cbind(TotalEarnings, OnlineEarnings, TotalPlayers, TotalTournaments)~Genre, data=esport)
summary(man)
summary.aov(man)

pairwise.t.test(esport$TotalEarnings, esport$Genre, p.adj="none")
pairwise.t.test(esport$OnlineEarnings, esport$Genre, p.adj="none")
pairwise.t.test(esport$TotalPlayers, esport$Genre, p.adj="none")
pairwise.t.test(esport$TotalTournaments,  esport$Genre, p.adj="none")

pairwise.t.test(esport$TotalEarnings, esport$Genre, p.adj="none")$p.value<0.05/225
pairwise.t.test(esport$OnlineEarnings, esport$Genre, p.adj="none")$p.value<0.05/225
pairwise.t.test(esport$TotalPlayers, esport$Genre, p.adj="none")$p.value<0.05/225
pairwise.t.test(esport$TotalTournaments,  esport$Genre, p.adj="none")$p.value<0.05/225


```
```yaml
Checking MANOVA assumptions:
1. Random samples, independent observations, yes we can assume this.
2. Multivariate normality of DVs, no, some groups have less than 25 observations, namely for Battle Royale,	Collectible Card Game, Multiplayer Online Battle Arena,	Puzzle Game, Role-Playing Game, Third-Person Shooter.
3. Homogeneity of within-group covariance matrices, yes we can assume this.
4. Linear relationships among DVs, it's possible to assume this. I would assume that a more popular game (more players and more tournaments) would have greater earnings (total and online)
5. No extreme univariate or multivariate outliers, yes we can assume this. 
6. No multicollinearity (i.e., DVs should not be too correlated), yes we can assume this
```
Assume MANOVA to be an appropriate analysis technique. A one-way MANOVA was conducted to determine the effect of the `Genre`
on tournament elements: `TotalEarnings`, `OnlineEarnings`, `TotalPlayers`, `TotalTournaments`. All the elements differ by `Genre` except `TotalTournaments` since every P-value is less than 0.001. 
Significant differences were found among the `Genre`s for at least one of the dependent variables. Pillai trace = 0.21773, pseudo F(40,2036), p = 3.502e-09 < 0.001. Univariate ANOVAs for each dependent variable were conducted as follow-up tests to the MANOVA, using the Bonferroni method for controlling Type I error rates for multiple comparisons. The univariate ANOVAs for each element were also significant at 0.001 significance level. 
1 MANOVA + 4 ANOVAs + 4 pairwise t tests (4*(10+9+8+7+6+5+4+3+2+1)) = 225 tests, so use 0.05 / 225 = 0.0002 significance.

Post hoc analysis was performed conducting pairwise comparisons to determine which `Genre`s differed in elements. When using Bonferroni = 0.05 / 225 = 0.0002. The probability that at least 1 type 1 error occurred is 1-.95^225 or 0.9999, as we have 225 hypothesis tests. 

After correction:

For `TotalEarnings`: The results that are significant are Multiplayer Online Battle Arena and Collectible Card Game, Multiplayer Online Battle Arena and Fighting Game, Multiplayer Online Battle Arena and First-Person Shooter, Multiplayer Online Battle Arena and Puzzle Game, Multiplayer Online Battle Arena and Racing, Multiplayer Online Battle Arena and Sports, Multiplayer Online Battle Arena and Strategy.

For `OnlineEarnings`: The results that are significant are Multiplayer Online Battle Arena and Collectible Card Game,  Multiplayer Online Battle Arena and First Person Shooter,  Multiplayer Online Battle Arena and Fighting Game, Multiplayer Online Battle Arena and Puzzle Game, Multiplayer Online Battle Arena and Racing, Multiplayer Online Battle Arena and Sports, Multiplayer Online Battle Arena and Strategy.

For `TotalPlayers`: There are no significant results.

For `TotalTournaments`: There are no significant results.

## Randomization Test!
I want to know if there is an association with the `Genre` of game and `TotalEarnings` for the prize pool, specifically for the `Genre`s: Battle Royale and	Multiplayer Online Battle Arena since they are the two highest prized genres. 
So I want to test whether there was a difference in mean `TotalEarnings` between the two Genres.

*Null hypothesis* : There is no difference in the mean TotalEarnings between Battle Royale and	Multiplayer Online Battle Arena.

*Alternative hypothesis* : There is a significant difference in the mean TotalEarnings between Battle Royale and	Multiplayer Online Battle Arena.
```{r fig.width=6, fig.height=6, fig.align='center'}
esport %>% group_by(Genre) %>% summarize(n=mean(TotalEarnings))
br <- esport %>% filter(Genre=="Battle Royale") %>% select(Genre,TotalEarnings)
moba <- esport %>% filter(Genre=="Multiplayer Online Battle Arena") %>% select(Genre,TotalEarnings)

comp <- rbind(br,moba)
ggplot(comp,aes(TotalEarnings,fill=Genre))+geom_histogram(bins=6.5)+
facet_wrap(~Genre,ncol=2)+theme(legend.position="none")

rand_dist<-vector()
for(i in 1:5000){
  new<-data.frame(te=sample(comp$TotalEarnings),genre=comp$Genre)
  rand_dist[i]<-mean(new[new$genre=="Battle Royale",]$te)-
  mean(new[new$genre=="Multiplayer Online Battle Arena",]$te)}
diffmeans <- esport %>% group_by(Genre) %>% filter(Genre=="Battle Royale" | Genre=="Multiplayer Online Battle Arena") %>% summarize(means=mean(TotalEarnings)) 
11973998- 17728953
diffmeans
{hist(rand_dist,main="",ylab=""); abline(v = c(-5754955, 5754955),col="red")}
mean(rand_dist>5754955 | rand_dist < -5754955)

t.test(data=comp,TotalEarnings~Genre)
```
The randomization test has less power so the p-value is higher. The high p-value suggests that there is no significant difference in means. There is high variance in the difference in means. 



## Linear Regression Modelling!
```{r fig.width=6, fig.height=6, fig.align='center'}
esport$TotalEarnings_c = esport$TotalEarnings-mean(esport$TotalEarnings, na.rm=T)
esport$OnlineEarnings_c = esport$OnlineEarnings-mean(esport$OnlineEarnings, na.rm=T)

fit <- lm(TotalPlayers~TotalEarnings_c*OnlineEarnings_c,data=esport)
```

## Interpreting Coefficients! 
```{r fig.width=6, fig.height=6, fig.align='center'}
summary(fit)
```
The intercept is 267.6, which suggests that a tournament with mean `TotalEarnings` and mean `OnlineEarnings` will have about 267-268 players. The coefficient for `TotalEarnings_c` means that for every $1 increase in mean prize money, there will be an increase of 6.066e-05 of a player. The coefficient for `OnlineEarnings_c` means that for every $1 increase in mean prize money, there will be 8.034e-05 of a player. The interaction of `TotalEarnings_c` and `OnlineEarnings_c` suggests that there is a decrease of -5.479e-13 of a player for every $1 increase in both `TotalEarnings_c` and `OnlineEarnings_c`. 

Below mean `OnlineEarnings_c` leads to an increase in the slope of total earnings and players.
Above mean `OnlineEarnings_c`leads to a decrease in the slope of `TotalEarnings_c` and `TotalPlayers`. 
It is interesting to see that below mean `OnlineEarnings_c` has the steepest slope, followed by the mean `OnlineEarnings_c`and then above the mean `OnlineEarnings_c. 

## Plotting Linear Regression!
```{r fig.width=6, fig.height=3, fig.align='center'}
library(interactions)
interact_plot(fit,pred =  TotalEarnings_c, modx = OnlineEarnings_c)
```

The coefficient of determination, R-squared, is the proportion of the variation that explained by the regression. Multiple R-squared:  0.788,	Adjusted R-squared:  0.7867. Thus, this linear model accounts for about 78% of the variation in the data. 

## Checking Assumptions! 
Check assumptions of linearity, normality, and homoscedasticity graphically.

## Linearity?
```{r fig.width=6, fig.height=6, fig.align='center'}
esport %>% ggplot(aes(TotalEarnings_c,TotalPlayers)) + geom_point()
esport %>% ggplot(aes(OnlineEarnings_c,TotalPlayers)) + geom_point()
```
It is a little hard to tell because of the outliers. But it looks like both predictors, `TotalEarnings` and `OnlineEarnings` should probably fail the linearity assumption. There is a hint of slight linearity but is hard to tell with the outliers. 

## Normality?
```{r fig.width=6, fig.height=6, fig.align='center'}
resids1 <- lm(TotalPlayers~OnlineEarnings, data=esport)$residuals
ggplot()+geom_histogram(aes(resids1),bins=50)

fitted1<-lm(TotalPlayers~OnlineEarnings, data=esport)$fitted.values
ggplot()+geom_point(aes(fitted1,resids1))


resids2<- lm(TotalPlayers~TotalEarnings, data=esport)$residuals
ggplot()+geom_histogram(aes(resids2),bins=50)

fitted2<-lm(TotalPlayers~TotalEarnings, data=esport)$fitted.values
ggplot()+geom_point(aes(fitted2,resids2))
```
The histograms are really skewed for both predictors so they do not look normal. It looks like there is large variance in residuals for both predictors as well. 

## Homoscedasticity?
```{r fig.width=6, fig.height=6, fig.align='center'}
library(sandwich)
library(lmtest)
fit<-lm(TotalPlayers~TotalEarnings_c*OnlineEarnings_c,data=esport)
bptest(fit) #H0: homoskedastic
coeftest(fit, vcov = vcovHC(fit))[,1:2]
```
The calculated p value for Breusch-Pagan (bp) test is < 2.2e-16, which we can reject the null that the data is homoscedastic. Thus, the data is not homoscedastic but heteroscedastic.

The data fails all assumptions...

## Recomputing Regression!
Need Heteroscedasticity Robust Standard Errors and Bootstrapped SEs.
    
```{r fig.width=6, fig.height=6, fig.align='center'}
coeftest(fit)
coeftest(fit, vcov=vcovHC(fit))

```
The original model said that all coefficents were significant in the regression. After using Robust SE, we see that only the intercept remains significant at the 0.01 level. The SE increased from the original to the Robust SE.
    
## Bootstrap SE!

```{r fig.width=6, fig.height=6, fig.align='center'}
set.seed(1234)
boot_dat<- sample_frac(esport, replace=T)

samp_distn<-replicate(5000, {
boot_dat <- sample_frac(esport, replace=T)
fit <- lm(TotalPlayers~TotalEarnings_c*OnlineEarnings_c, data=boot_dat) 
coef(fit) 
})
samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)

samp_distn %>% t %>% as.data.frame %>% pivot_longer(1:4) %>% group_by(name) %>%
summarize(lower=quantile(value,.025), upper=quantile(value,.975))

```
I chose to resample observations. The SE through Bootstrap are smaller than the SE through Robust SE. By observing that our bootstrap SEs for TotalEarnings_c, OnlineEarnings_c, are inside the range of 95% CI, these estimates are insignificant. However, the estimate for the intercept and  TotalEarnings_c:OnlineEarnings_c is outside of this range, making it significant. 

## Logistic Regression Modelling!
I want to see how well a logistic model can predict a "highly prized game". I define this by a game whose TotalEarnings are greater than 10,000 USD. 
    
    
```{r fig.width=6, fig.height=6, fig.align='center'}
esportb <- esport %>% mutate(y = ifelse(TotalEarnings>10000,1,0))
esportb <- esportb %>% filter(Genre != "Role-Playing Game") 
esportb %>% group_by(Genre) %>% summarize(n())
lrm <- glm(y~ Genre + TotalTournaments, data=esportb, family="binomial")
coeftest(lrm)
exp(coef(lrm))

```
logodds =  0.601096 + Collectible Card Game(-2.123686) + Fighting Game(-2.946988) + First-Person Shooter(-0.739829) + Multiplayer Online Battle Arena(-0.764863) + Puzzle Game(-3.502153) + Racing(-0.633730) + Sports(-0.225241) + Strategy(-1.060934) + Third-Person Shooter(0.234720) + TotalTournaments(0.185386)

Battle Royale is the `Genre` used as reference. 
The odds of Battle Royale to Collectible Card Game is 0.11959001. The odds of Battle Royale to Fighting Game is 0.05249758. As we continue this interpretation for the rest of the different `Genre`s, it is obvious that all Genres but 1, Third-Person Shooter, have less odds of being a highly prized game than the reference `Genre`: Battle Royale. 

An increase in 1 `TotalTournaments` affects the logodds by an increase of 0.185386. So the odds of a tournament being highly prized is increased by 1.20368262. 

Note: ended up removing Role-Playing Game from Genre to improve model. 

## Confusion Matrix!
```{r fig.width=6, fig.height=6, fig.align='center'}
prob <- predict(lrm,type="response")
table(predict=as.numeric(prob>.5),truth=esportb$y)%>%addmargins
```

```{r fig.width=6, fig.height=6, fig.align='center'}
class_diag<-function(probs,truth){
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]

  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,auc)
}
class_diag(prob,esportb$y)
```

The Accuracy is 0.8346304. 
The Sensitivity (TPR) is 0.9195046. 
The Specificity (TNR) is 0.6910995. 
The Precision (PPV) is 0.8342697. 
The AUC is 0.8969089. This means that this is a good model for predicting if the game is having `TotalEarnings` > 10000. 

```{r fig.width=6, fig.height=6, fig.align='center'}
esportb$logit <- predict(lrm)
esportb$outcome <- factor(esportb$y,levels=c("0","1"))
ggplot(esportb,aes(logit, fill=outcome))+geom_density(alpha=.3)+
  geom_vline(xintercept=0,lty=2) + xlim(-1, 100)
ggplot(esportb,aes(logit, fill=outcome))+geom_density(alpha=.3)+
  geom_vline(xintercept=0,lty=2) + xlim(-1, 10)
```

```{r fig.width=6, fig.height=6, fig.align='center'}
library(plotROC)
ROCplot<-ggplot(esportb)+geom_roc(aes(d=y,m=prob), n.cuts=0)
ROCplot
calc_auc(ROCplot)
```
This AUC matches the AUC I got from using the class_diag() function. With this AUC value, I can say that this is a good model for predicting if the game is having `TotalEarnings` > 10000 based on the predictors of `Genre` and `TotalTournaments`.
  
## Using many predictors on Logistic Regression!  
Now I predict if a game's tournament will have `TotalEarnings` > 10000 based on the predictors: `Genre` + `TotalTournaments` + `OnlineEarnings` + `TotalPlayers` + `ReleaseDate`.
    
```{r fig.width=6, fig.height=6, fig.align='center'}
lrm2 <- glm(y~ Genre + TotalTournaments + OnlineEarnings + TotalPlayers + ReleaseDate, data=esportb, family="binomial")
coeftest(lrm2)
exp(coef(lrm2))
prob2 <- predict(lrm2,type="response")
table(predict=as.numeric(prob2>.5),truth=esportb$y)%>%addmargins
class_diag(prob2,esportb$y)
```

The Accuracy is 0.9319066. 
The Sensitivity (TPR) is 0.9318885. 
The Specificity (TNR) is 0.9319372. 
The Precision (PPV) is 0.9585987. 
The AUC is 0.9848929. This means that this is a great model for predicting if the game is having `TotalEarnings` > 10000. 

## 10-fold CV!
```{r fig.width=6, fig.height=6, fig.align='center'}
set.seed(1234)
k = 10


data <- esportb[sample(nrow(esportb)),] 
folds <- cut(seq(1:nrow(esportb)),breaks=k,labels=F) 

diags <- NULL
for(i in 1:k){         
train <- data[folds!=i,] 
test <- data[folds==i,]  

truth <- test$y

fit <- glm(y ~ Genre + TotalTournaments + OnlineEarnings + TotalPlayers + ReleaseDate, data=train, family="binomial")
probs <- predict(fit, newdata = test, type="resp")

diags <- rbind(diags,class_diag(probs,test$y)) 
}

summarize_all(diags,mean)
```
The AUC from the original model was 0.9848929. After 10-fold CV, the AUC is 0.9814307, which is a slight decrease. Since the model is still great and the difference is quite small, I conclude that this model does not show signs of overfitting. 

The average out-of-sample classification diagnostics are:
The Accuracy is 0.9183635. 
The Sensitivity (TPR) is 0.9225357. 
The Specificity (TNR) is 0.9147702. 
The Precision (PPV) is 0.9451259. 

## LASSO! 

```{r fig.width=6, fig.height=3, fig.align='center'}
library(glmnet)
set.seed(1234)

z <- as.matrix(esportb$y) 
x <- model.matrix(z ~ Genre + TotalTournaments + OnlineEarnings + TotalPlayers + ReleaseDate, data=esportb)[,-1]
head(x)
cv <- cv.glmnet(x, z, family="binomial")
cv
{plot(cv$glmnet.fit, "lambda", label=TRUE); abline(v = log(cv$lambda.1se)); abline(v = log(cv$lambda.min),lty=2)}
lasso <- glmnet(x, z, family="binomial", lambda=cv$lambda.min)
lasso
coef(lasso)

lasso_dat <- esportb %>% mutate(CollectibleCardGame = ifelse(Genre=="Collectible Card Game", 1, 0) ) %>% mutate(FightingGame = ifelse(Genre=="Fighting Game", 1, 0) ) %>% mutate(FPS = ifelse(Genre=="First-Person Shooter", 1, 0) )%>% mutate(MOBA = ifelse(Genre=="Multiplayer Online Battle Arena", 1, 0) ) %>% mutate(PuzzleGame = ifelse(Genre=="Puzzle Game", 1, 0) ) %>% mutate(Racing = ifelse(Genre=="Racing", 1, 0) ) %>% mutate(Sports = ifelse(Genre=="Sports", 1, 0) ) %>% mutate(MOBA = ifelse(Genre=="Multiplayer Online Battle Arena", 1, 0) ) %>% mutate(MOBA = ifelse(Genre=="Multiplayer Online Battle Arena", 1, 0) ) %>% mutate(Strategy = ifelse(Genre=="Strategy", 1, 0) ) %>% mutate(TPS = ifelse(Genre=="Third-Person Shooter", 1, 0) ) %>% select(CollectibleCardGame:Racing, Sports:TPS, OnlineEarnings:ReleaseDate) 
```
LASSO shows that all of the Genres and selected predictors (except `TotalTournaments`) have nonzero coeffient estimates. It is interesting that the lambda.min reduces the coefficients by 1 while lambda.1se retains all of the coefficients. 

## 10-fold CV for LASSO!
```{r fig.width=6, fig.height=6, fig.align='center'}
set.seed(1234)
k = 10


data <- esportb[sample(nrow(esportb)),] 
folds <- cut(seq(1:nrow(data)),breaks=k,labels=F) 

diags <- NULL
for(i in 1:k){        
train <- data[folds!=i,]
test <- data[folds==i,]  

truth <- test$y

fit <- glm(y ~ Genre + OnlineEarnings + TotalPlayers + ReleaseDate, data=train, family="binomial")
probs <- predict(fit, newdata = test, type="resp")

diags <- rbind(diags,class_diag(probs,test$y))
}

summarize_all(diags,mean) 
```
The average classification diagnostics are:
The Accuracy is 0.9183635. 
The Sensitivity (TPR) is 0.9222326. 
The Specificity (TNR) is 0.9147702. 
The Precision (PPV) is 0.9449871. 
The AUC is 0.9801063 which is less than the logistic regressions above, but still proves to be a great model. 

## Conclusion

Overall, it was really interesting to model the data from the esports tournament data set. I created a great model for predicting if a given game will be highly prized based on these predictors: `Genre` + `TotalTournaments` + `OnlineEarnings` + `TotalPlayers` + `ReleaseDate`. 
